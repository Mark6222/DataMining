{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4653890a",
      "metadata": {},
      "source": [
        "# K Nearest Neighbours\n",
        "\n",
        " * Animation of KNN\n",
        " * Used to generate images for slides"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b814c7e0",
      "metadata": {},
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d589443",
      "metadata": {
        "tags": [
          "load"
        ]
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "sns.set_context(\"talk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16907fb1",
      "metadata": {},
      "source": [
        "Load in a dataset\n",
        " * Should have numerical features\n",
        " * Labeled (supervised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316b446f",
      "metadata": {
        "tags": [
          "dataset"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "dataset_name = \"IRIS\"\n",
        "X, y, target_names = iris.data, iris.target, iris.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcdf7b41",
      "metadata": {},
      "source": [
        "KNN works in arbitrary dimensions, but to visualise it we need to drop down to two. Using Linear Discrimant Analysis (LDA) we can find the best two dimensions to separate the classes, i.e., the best direction to view the data so that the classes are separated as much as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734b1f85",
      "metadata": {
        "tags": [
          "lda"
        ]
      },
      "outputs": [],
      "source": [
        "# drop down to 2D so we can visualise KNN\n",
        "if False:\n",
        "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "    lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "    X = lda.fit_transform(X, y)\n",
        "    axis_labels = None\n",
        "else:\n",
        "    X = X[:,:2]\n",
        "    axis_labels = [\"Sepal length (cm)\", \"Sepal width (cm)\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e039cb3",
      "metadata": {},
      "source": [
        "FOR YOU: Lookup up discriminant analysis online? How is it similiar to and how is it different to classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e02b7b65",
      "metadata": {},
      "source": [
        "Scaling features is necessary before KNN to avoid undue influence by the dominant features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60298dd1",
      "metadata": {
        "tags": [
          "scale"
        ]
      },
      "outputs": [],
      "source": [
        "# scale features (to mean=0, std=1)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a6b7ec3",
      "metadata": {},
      "source": [
        "randomize the order observation order - for later visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7939149f",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "idx = np.random.permutation(range(len(y)))\n",
        "X, y = X[idx], y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d65c08d0",
      "metadata": {},
      "source": [
        "The following provides an interact means of trying out various settings,\n",
        "using GUI controls like sliders, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "211f5407",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "import matplotlib.patches as mpatches\n",
        "from collections import Counter\n",
        "\n",
        "n = X.shape[0]\n",
        "n_classes = len(target_names)\n",
        "\n",
        "markers = ['^', 's', '*']\n",
        "colors =   ['#377eb8', '#4daf4a', '#a65628', '#984ea3','#999999', '#e41a1c', '#dede00']\n",
        "\n",
        "m = widgets.IntSlider(value=10, min=1, max=n-1, step=1)\n",
        "k = widgets.IntSlider(value=1, min=1, max=20, step=1)\n",
        "summary = widgets.Textarea(value='', layout={'height':'150px', 'width': 'auto'}, disabled=False)\n",
        "ui = widgets.VBox([\n",
        "    widgets.HBox([\n",
        "        widgets.VBox([widgets.Label('Number of observations in train set: $m$'), m]),\n",
        "        widgets.VBox([widgets.Label('Number of neighbours: $k$'), k])\n",
        "    ]),\n",
        "    summary])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c0d5a4",
      "metadata": {},
      "source": [
        "Prepare a utility function `f` to draw a typical setup, settings controlled by input parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8efa1b8",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def f(m,k, show_fig=True, save_fig=False, show_region=True, size=100):\n",
        "    \n",
        "    global summary\n",
        "    \n",
        "    message = \"\"\n",
        "    if k>m:\n",
        "        message += f\"Reducing k to {m}, since number of neighbours cannot be bigger than number of observation in train set.\\n\"\n",
        "        k = m\n",
        "    \n",
        "    # train set consists of first m observations\n",
        "    X_train, y_train = X[:m], y[:m]\n",
        "\n",
        "    # new observation is (m+1)(th) observation\n",
        "    x_new =  X[m]\n",
        "\n",
        "    # compute distances from new point to all others in train\n",
        "    distances = np.linalg.norm(X_train - x_new,axis=1)\n",
        "    neighbours = sorted(zip(distances,y_train), key=lambda x: x[0])\n",
        "\n",
        "    # get min radius to reach k nearest neighbours \n",
        "    radius = neighbours[k-1][0]\n",
        "\n",
        "    message +=  f\"Location of new observation is ({x_new[0]:.2f}, {x_new[1]:.2f})\\n\" \\\n",
        "        f\"Radius needed to reach {k} nearest neighbours = {radius:.2f}\"\n",
        "    message += \"\\nCounting neighbours ...\"\n",
        "    counts = Counter([a[1] for a in neighbours[:k]])\n",
        "    max_count = max([v for _,v in counts.items()])\n",
        "    max_class = [c for c,v in counts.items() if v==max_count]\n",
        "    \n",
        "    for i in range(n_classes):\n",
        "         message += f\"\\n\\t{target_names[i]:20s} {counts[i]:3d} {'MAX' if i in max_class else ''}\"\n",
        "    if len(max_class)==1:\n",
        "        message += f\"\\n{k} nearest neighours suggests that new observation should be in class '{target_names[max_class[0]]}'.\"\n",
        "    else:\n",
        "        message += f\"\\nHave tie in {k} nearest neighours, reduce k by one and rerun.\"\n",
        "    # comment on unsafe k\n",
        "    if k % n_classes==0:\n",
        "        message += f\"\\nNote: Number of neighbours k={k} should not be a multiple of number of classes = {n_classes}.\"\n",
        "    \n",
        "    if show_fig or save_fig:\n",
        "        fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
        "    \n",
        "        # add a circle\n",
        "        if show_region:\n",
        "            circle = plt.Circle(x_new, radius, color='r', alpha=0.2)\n",
        "            ax.add_patch(circle)\n",
        "        \n",
        "        for i in range(n_classes):\n",
        "            plt.scatter(X_train[y_train==i, 0], X_train[y_train==i, 1], s=size, marker=markers[i], alpha=.8, color=colors[i],  label=target_names[i])\n",
        "        plt.scatter(x_new[0], x_new[1], marker='$?$', s=size, alpha=.8, color='red')\n",
        "\n",
        "        plt.legend(loc='lower left', shadow=False, scatterpoints=1, frameon=True)\n",
        "        #plt.axis('equal')\n",
        "        plt.ylim(-2.6,2.6)\n",
        "        plt.xlim(-2.6,2.6)\n",
        "        if axis_labels is not None:\n",
        "            plt.xlabel(axis_labels[0])\n",
        "            plt.ylabel(axis_labels[1])\n",
        "        plt.title(f'{dataset_name} dataset (m={m}, k={k})');\n",
        "\n",
        "    summary.value = message\n",
        "        \n",
        "    if save_fig:\n",
        "        filename = f\"output/knn_{dataset_name}_{m}_{k}_{int(show_region)}.pdf\"\n",
        "        plt.savefig(filename, bbox_inches=\"tight\")\n",
        "    if not show_fig: plt.close()\n",
        "\n",
        "    return {\"X_train\":X_train, \"y_train\":y_train, \"x_new\":x_new, \"distances\": distances, \"counts\": counts}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659c4a11",
      "metadata": {},
      "source": [
        "Now apply the interactive widget to f (to choose its input argument values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9498d696",
      "metadata": {},
      "outputs": [],
      "source": [
        "out = widgets.interactive_output(f, {'m': m, 'k': k})\n",
        "display(ui, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4e82a0d",
      "metadata": {},
      "source": [
        "## Visualising KNN in action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa9ed20",
      "metadata": {},
      "outputs": [],
      "source": [
        "f(26,1, show_fig=1, save_fig=1, show_region=0, size=200);\n",
        "f(26,1, show_fig=0, save_fig=1, show_region=0, size=200);\n",
        "f(26,1, show_fig=0, save_fig=1, show_region=1, size=200);\n",
        "f(26,3, show_fig=0, save_fig=1, show_region=1, size=200);\n",
        "f(26,5, show_fig=0, save_fig=1, show_region=1, size=200);\n",
        "f(26,7, show_fig=0, save_fig=1, show_region=1, size=200);\n",
        "f(26,9, show_fig=0, save_fig=1, show_region=1, size=200);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78dd1afc",
      "metadata": {},
      "source": [
        "## Decision Boundaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4cea5b2",
      "metadata": {
        "title": "[msrkdown]"
      },
      "outputs": [],
      "source": [
        "# First import KNN and the iris data (which is one of the standard datasets provided with sklearn) and prepare it for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268d1867",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "dataset_name = \"IRIS\"\n",
        "X, y, target_names = iris.data[:, :2], iris.target, iris.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47045559",
      "metadata": {},
      "source": [
        "Choose paler colours (`cmap_light`) for the regions, and strong colours (`cmap_bold`) for the data itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5dcedb3",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
        "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25829ea6",
      "metadata": {},
      "source": [
        "The `decision_boundaries` function gathers together the steps needed to display the decision boundaries on a 100x100 mesh grid "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e04970",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def decision_boundaries(k, show_fig=True):\n",
        "\n",
        "#\n",
        "# Create the nearest neighbors classifier object for a specific k number of neighbors\n",
        "# Then apply it to the data X (sepal length and width) and y (iris labels)\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X, y)\n",
        "\n",
        "#\n",
        "# Layout a rectangular 100x100 grid that covers the entire range of the training data, leaving a margin of 0.1 on each boundary\n",
        "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
        "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
        "\n",
        "#\n",
        "# Looping over the mesh grid points, apply the knn model to predict the label for each grid point \n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "#\n",
        "# Now colour each grid point based on its prediced label (0,1,2), which picks out the relevant colour from the cmap_light colour map.\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light, shading='auto')\n",
        "\n",
        "#\n",
        "# Looping over the 3 labels...\n",
        "#   Overlay a plot of the relevant training set data points, using its own `marker` symbol and colour (from the `cmap_bold` colour map)\n",
        "#   Add labels and a title\n",
        "#   Save the figure, using a filename that is generated based on variables like `dataset_name` and `k`\n",
        "    for i in range(3):\n",
        "        plt.scatter(X[y==i,0], X[y==i, 1], c=['#FF0000', '#00FF00', '#0000FF'][i], marker=markers[i])\n",
        "        plt.xlabel('sepal length (cm)')\n",
        "        plt.ylabel('sepal width (cm)')\n",
        "        plt.title(f\"{dataset_name} k-NN decision boundaries ($k={k}$)\")\n",
        "        plt.axis('tight')\n",
        "        plt.savefig(f\"output/knn_{dataset_name}_decision_boundary_{k}.pdf\")\n",
        "# The following code is commented out because it does not seem to work with the notebook_exporter\n",
        "#        if show_fig:\n",
        "#            plt.show()\n",
        "# Actually we don't need this anyway, so we can comment it out\n",
        "#        plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1170295a",
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [1,3,5,7,17]:\n",
        "    decision_boundaries(k,show_fig=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b49c7e1",
      "metadata": {},
      "source": [
        "FOR YOU: What happens to the decision boundaries as k increases? How might you find an optimal value of k?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db6de94",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
