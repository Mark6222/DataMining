{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d344bc13",
      "metadata": {},
      "source": [
        "# Querying `Series`\n",
        "\n",
        "Now that we have seen how to create a Series and how data is represented in one, we will want to apply operations like searching for values in the series. In this notebook we conside the structure of the Series, how to query and merge Series objects together, and the importance of thinking about parallelization when engaging in data science programming.\n",
        "\n",
        "A pandas Series can be queried either by the index position or the index label. If you don't give an index to the series when querying, the position and the label are effectively the same values. To query by numeric location, starting at zero, use the iloc attribute. To query by the index label, you can use the loc attribute. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9c852939",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Alice     Programming\n",
              "Bob      Cryptography\n",
              "Carol      Networking\n",
              "Dave        Databases\n",
              "dtype: object"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets start with an example. We'll use students enrolled in classes coming from a dictionary\n",
        "import pandas as pd\n",
        "students_classes = {'Alice': 'Programming',\n",
        "                   'Bob': 'Cryptography',\n",
        "                   'Carol': 'Networking',\n",
        "                   'Dave': 'Databases'}\n",
        "s = pd.Series(students_classes)\n",
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9a57b72d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Databases'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# So, for this series, if you wanted to see the fourth entry we would we would use the iloc \n",
        "# attribute with the parameter 3.\n",
        "s.iloc[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ed666973",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Networking'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If you wanted to see what class Carol has, we would use the loc attribute with a parameter \n",
        "# of Carol.\n",
        "s.loc['Carol']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71f4efc5",
      "metadata": {},
      "source": [
        "__Important__ Note that `iloc` and `loc` are not methods, they are attributes. So you don't use parentheses to query them, but square brackets instead, which is called the indexing operator. This calls a getter or setter for an item depending on the context of its use.\n",
        "\n",
        "This might seem confusing if you are used to languages, such as Java, where encapsulation of attributes, variables, and properties is common.\n",
        "\n",
        "Pandas tries to make our code a bit more readable and provides a sort of smart syntax using the indexing operator directly on the series itself. For instance, if you pass in an integer parameter, the operator will behave as if (infer!) you want it to query via the iloc attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3aab3080",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\marky\\AppData\\Local\\Temp\\ipykernel_292960\\3172538273.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  s[3]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Databases'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "93e8c0a1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Networking'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If you pass in an object, it will query as if you wanted to use the label based loc attribute.\n",
        "s['Carol']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52285870",
      "metadata": {},
      "source": [
        "So what happens if your index is a list of integers? This is a bit complicated and Pandas can't determine automatically whether you're intending to query by index position or index label. So \n",
        "you need to be careful when using the indexing operator on the Series itself. The safer option is to be more explicit and use the iloc or loc attributes directly.\n",
        "\n",
        "Here's an example using class and their classcode information, where classes are indexed by classcodes, in the form of integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "41e5f3b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_code = {99: 'Programming',\n",
        "              100: 'Cryptography',\n",
        "              101: 'Networking',\n",
        "              102: 'Databases'}\n",
        "s = pd.Series(class_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c508b69",
      "metadata": {},
      "source": [
        "If we try and call s[0] we get a key error because there's no item in the classes list with an index of zero, instead we have to call iloc explicitly if we want the first item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e025a3fd",
      "metadata": {
        "tags": [
          "raises-exception"
        ]
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mD:\\Solfware\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m s[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32mD:\\Solfware\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
            "File \u001b[1;32mD:\\Solfware\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
            "File \u001b[1;32mD:\\Solfware\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 0"
          ]
        }
      ],
      "source": [
        "s[0] "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74baa40e",
      "metadata": {},
      "source": [
        "So, that didn't call s.iloc[0] underneath as one might expect, instead it \n",
        "generates an error.\n",
        "\n",
        "Now we know how to get data out of the series, how about working with the data. A common task is to want to consider all of the values inside of a series and do some sort of operation. This could be trying to find a certain number, or summarizing data or transforming the data in some way.\n",
        "\n",
        "A typical programmatic approach to this would be to iterate over all the items in the series, and invoke the operation one is interested in. For instance, we could create a Series of integers representing student grades, and just try and get an average grade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "09a6fe3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75.0\n"
          ]
        }
      ],
      "source": [
        "grades = pd.Series([90, 80, 70, 60])\n",
        "\n",
        "total = 0\n",
        "for grade in grades:\n",
        "    total+=grade\n",
        "print(total/len(grades))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2174892",
      "metadata": {},
      "source": [
        "This works, but it's slow. Modern computers can do many tasks simultaneously, especially, but not only, mathematical computation on collections of numbers.\n",
        "\n",
        "Pandas and the underlying numpy libraries support a method of computation called vectorization. Vectorization works with most of the functions in the numpy library, including the sum function.\n",
        "\n",
        "Here's how we would rewrite the code using the numpy `sum()` method. First we need to import the numpy module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "52854889",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Then we just call np.sum and pass in an iterable item.\n",
        "# In this case, our panda series.\n",
        "\n",
        "total = np.sum(grades)\n",
        "print(total/len(grades))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69402228",
      "metadata": {},
      "source": [
        "Now both of these methods create the same value, but is one actually faster? The Jupyter Notebook has a magic function which can help. \n",
        "\n",
        "First, let's create a big series of random numbers. This is used a lot when demonstrating techniques with Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b4377a17",
      "metadata": {},
      "outputs": [],
      "source": [
        "numbers = pd.Series(np.random.randint(0,1000,10000))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea069c39",
      "metadata": {},
      "source": [
        "Now lets look at the top five items in that series to make sure they actually seem random. We can do this with the `head()` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dbf83242",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    342\n",
              "1    208\n",
              "2     29\n",
              "3    419\n",
              "4    795\n",
              "dtype: int32"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numbers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84275b18",
      "metadata": {},
      "source": [
        "We can actually verify that length of the series is correct using the len function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "44c49d85",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79cc2411",
      "metadata": {},
      "source": [
        "Ok, we're confident now that we have a big series. The interpreter has something called __magic functions__ that begin with a percentage sign. If we type this sign and then hit the Tab key, you can see a list of the available magic functions. You could write your own magic functions too, \n",
        "but that is out of scope....\n",
        "\n",
        "A __cellular magic function__ starts with two \n",
        "percentage signs and applies to the code in the current notebook cell. The function we use is called `timeit`. This function will run our code a few times to determine, on average, how long it takes.\n",
        "\n",
        "Let's run `timeit` with our original iterative code. You can give timeit the number of loops that you would like to run. By default, it is 1,000 loops. For this purpose, 100 runs is sufficient. Note that in order to use a cellular magic function, it has to be the first line in the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7d4259cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.39 ms ± 401 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 100\n",
        "total = 0\n",
        "for number in numbers:\n",
        "    total+=number\n",
        "\n",
        "total/len(numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70ff2cce",
      "metadata": {},
      "source": [
        "Timeit ran the code and it doesn't seem to take very long. Will vectorization do better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "883af6eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "85.9 μs ± 25.1 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 100\n",
        "total = np.sum(numbers)\n",
        "total/len(numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc323783",
      "metadata": {},
      "source": [
        "On my machine, vectorization is 10-15 times faster than loop code. Students should look for vectorisation opportunities, favour parallel computing features and start thinking in functional programming terms.\n",
        "\n",
        "Vectorization allows the computer to execute multiple instructions\n",
        "at once, and with high performance chips, especially graphics cards, you can get dramaticspeedups. Modern graphics cards can run thousands of instructions in parallel.\n",
        "\n",
        "A Related feature in pandas and numpy is called _broadcasting_. With broadcasting, you can apply an operation to every value in the series, changing the series. For instance, if we wanted to increase every random variable by 2, we could do so quickly using the += operator \n",
        "directly on the Series object. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d65eb0a3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    342\n",
              "1    208\n",
              "2     29\n",
              "3    419\n",
              "4    795\n",
              "dtype: int32"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's look at the head of our series\n",
        "numbers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9fdf38a2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    344\n",
              "1    210\n",
              "2     31\n",
              "3    421\n",
              "4    797\n",
              "dtype: int32"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# And now lets just increase everything in the series by 2\n",
        "numbers+=2\n",
        "numbers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18875e9b",
      "metadata": {},
      "source": [
        "The procedural way of doing this would be to iterate through all of the items in the series and increase the values directly. Pandas does support iterating through a series much like a dictionary, allowing you to unpack values easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c0c643d4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    346\n",
              "1    212\n",
              "2     33\n",
              "3    423\n",
              "4    799\n",
              "dtype: int32"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can use the items() function which returns a label and value \n",
        "for label, value in numbers.items():\n",
        "    # in the early version of pandas we would use the set_value() function\n",
        "    # in the current version, we use the iat() or at() functions,\n",
        "    numbers.iat[label]= value+2\n",
        "# And we can check the result of this computation\n",
        "numbers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81963fdf",
      "metadata": {},
      "source": [
        "So the result is the same, though you may notice a warning depending upon the version of\n",
        "pandas being used. But if you find yourself iterating pretty much *any time* in pandas,\n",
        "you should question whether you're doing things in the best possible way.\n",
        "\n",
        "Lets take a look at some speed comparisons. First, lets try five loops using the iterative approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5f75863a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67.7 ms ± 5.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10\n",
        "# we'll create a blank new series of items to deal with\n",
        "s = pd.Series(np.random.randint(0,1000,1000))\n",
        "# And we'll just rewrite our loop from above.\n",
        "for label, value in s.items():\n",
        "    s.loc[label]= value+2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf9cb11",
      "metadata": {},
      "source": [
        "Now lets try that using the broadcasting methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b5c80457",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "385 μs ± 137 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10\n",
        "# We need to recreate a series\n",
        "s = pd.Series(np.random.randint(0,1000,1000))\n",
        "# And we just broadcast with +=\n",
        "s+=2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "795a132f",
      "metadata": {},
      "source": [
        "This is a dramatic improvement - over 100 times faster on my hardware. Not only is it significantly faster, but it is more concise and easier to read too. The typical mathematical operations you would expect are vectorized, and the numpy documentation outlines what it takes to create vectorized functions of your own. \n",
        "\n",
        "One last note on using the indexing operators to access series data. The .loc attribute lets \n",
        "you not only modify data in place, but also add new data as well. If the value you pass in as \n",
        "the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types. \n",
        "While it's important to be aware of the typing going on underneath, Pandas will automatically \n",
        "change the underlying NumPy types as appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e02e2c2c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0              1\n",
              "1              2\n",
              "2              3\n",
              "Databases    102\n",
              "dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here's an example using a Series of a few numbers. \n",
        "s = pd.Series([1, 2, 3])\n",
        "\n",
        "# We could add some new value, maybe a university course\n",
        "s.loc['Databases'] = 102\n",
        "\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9055da3",
      "metadata": {},
      "source": [
        "We see that mixed types for data values or index labels are no problem for Pandas. Since \"History\" is not in the original list of index values, `s.loc['Databases']` essentially creates a new element in the series, with the index named \"Databases\", and the value of 102\n",
        "\n",
        "_What happens if the index values are not unique?_\n",
        "\n",
        "In this regard, a pandas Series operates differently to a relational database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c7987fb2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Alice     Programming\n",
              "Bob      Cryptography\n",
              "Carol      Networking\n",
              "Dave        Databases\n",
              "dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets create a Series with students and the courses which they have taken\n",
        "students_classes = pd.Series({'Alice': 'Programming',\n",
        "                   'Bob': 'Cryptography',\n",
        "                   'Carol': 'Networking',\n",
        "                   'Dave': 'Databases'})\n",
        "students_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fdd84a5",
      "metadata": {},
      "source": [
        "Now lets create a Series just for some new student Eve, which lists all of the courses she has taken. We set the index to Eve for all the courses, and the data to be the names of courses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7469ff6f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Eve    Philosophy\n",
              "Eve          Arts\n",
              "Eve         Maths\n",
              "dtype: object"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eve_classes = pd.Series(['Philosophy', 'Arts', 'Maths'], index=['Eve', 'Eve', 'Eve'])\n",
        "eve_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20c5474",
      "metadata": {},
      "source": [
        "Finally, we can append all of the data in this new Series to the first using the `pd.concat()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "011b4174",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Alice     Programming\n",
              "Bob      Cryptography\n",
              "Carol      Networking\n",
              "Dave        Databases\n",
              "Eve        Philosophy\n",
              "Eve              Arts\n",
              "Eve             Maths\n",
              "dtype: object"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This code is deprecated!!\n",
        "#all_students_classes = students_classes.append(eve_classes)\n",
        "\n",
        "all_students_classes = pd.concat([students_classes, eve_classes])\n",
        "\n",
        "# This creates a series which has our original people in it as well as all of Kelly's courses\n",
        "all_students_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f03080a9",
      "metadata": {},
      "source": [
        "There are a couple of important considerations when concatenating series. First, Pandas will take the series and try to infer the best data types to use. In this example, everything is a string, so thereare no datatype inconsistencies. Second, the concat method returns a new series which is made up of the two appended together. This is a common pattern in pandas - by default returning a new object instead of modifying in place - and\n",
        "one you should come to expect.\n",
        "\n",
        "Previously, it was possible to use `.append()` on the first series but that could be confusing, because the result did not change the original series - it created a new one which needed to be stored in a `all_student_classes`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4045732f",
      "metadata": {},
      "source": [
        "Finally, we see that when we query the appended series for Eve, we don't get a single value, but a series (the rows asociated with Eve). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c37c8373",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Eve    Philosophy\n",
              "Eve          Arts\n",
              "Eve         Maths\n",
              "dtype: object"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_students_classes.loc['Eve']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b1f1a3",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "We've seen how to query the Series, with `.loc` and `.iloc`, that the Series is an indexed data structure, how to merge two Series objects together with `pd.concat()`, and the importance of vectorization.\n",
        "\n",
        "There is a lot more to Series, but the real strength of Pandas is its  two-dimensional data structure, the DataFrame. The DataFrame is very similar to the series object, but includes multiple columns of data, and is the structure that you'll spend the majority of your time working with when cleaning and aggregating data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a7ecac",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
